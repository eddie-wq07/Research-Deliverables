# Task #2: Merging PatentsView, DISCERN, and Clinical Trials

**Research Assistant Task** | Due: February 16, 2026
**Author:** Edward Jung

---

## Quick Start

### 1. Main Notebook
Start here: **`task2_patents_discern_merge.ipynb`**

This notebook contains:
- Complete workflow for merging PatentsView, DISCERN, and Clinical Trials
- Memory-efficient data processing using DuckDB
- AI patent classification (CPC codes + keywords)
- Firm-year aggregation
- Ready-to-use pandas code

### 2. Implementation Guide
For detailed documentation: **`IMPLEMENTATION_GUIDE.md`**

Includes:
- Data architecture design
- Memory efficiency best practices
- AI classification strategy
- DISCERN 2 integration steps
- Troubleshooting guide
- Validation checklist

---

## Deliverables

### Input Data
- `clinical_trial_sample (1).csv` - Clinical trials with sponsor names and GVKEY

### Output Files (Generated by Notebook)

**⭐ PRIMARY DELIVERABLES (what supervisor wants):**

1. **`firm_year_patents.csv`** ← MAIN OUTPUT
   - **Clean firm-year aggregated table**
   - One row per gvkey-year
   - Columns: gvkey, year, total_applications, ai_applications, ai_share, ai_dummy

2. **`firm_year_merged.csv`** ← ALTERNATIVE (includes trials)
   - Same as above + clinical trial metrics
   - Columns: all above + num_trials, avg_phase

3. **`task2_patents_discern_merge.ipynb`** ← REPRODUCIBLE WORKFLOW
   - Complete methodology and code
   - Shows how aggregated table was created

**Optional (internal validation only):**
- `patent_level_dataset.csv` - Detailed patent-level data (can be suppressed)

---

## Workflow Overview

```
1. Load Clinical Trials Data
   ↓
2. Download PatentsView Tables
   - g_application (patent applications)
   - pg_applicant_not_disambiguated (applicant names)
   - g_cpc_current (CPC codes for AI classification)
   - g_patent_abstract (for keyword search)
   ↓
3. Filter to 2000-2025
   ↓
4. Map Applicants to GVKEY
   - Use clinical trials sponsor mapping
   - (Optional: Integrate DISCERN 2)
   ↓
5. Classify AI Patents
   - Method 1: CPC codes (G06N*)
   - Method 2: Keyword search (title/abstract)
   - Combined: Flag if either method detects AI
   ↓
6. Aggregate to Firm-Year
   - Count total applications
   - Count AI applications
   - Calculate AI share and dummy
   ↓
7. Merge with Clinical Trials
   ↓
8. Export Datasets
```

---

## Data Architecture

### What the Supervisor Wants

**PRIMARY DELIVERABLE:** Firm-year aggregated table (gvkey × year)
- NOT patent-level details
- Clean summary table with aggregated counts

### Two-Layer Design (Internal Workflow)

#### Layer 1: Patent-Level (Internal)
```
Purpose: Classify AI patents
- Build internally for classification
- Not a final deliverable
- Can export optionally for validation
```

#### Layer 2: Firm-Year (PRIMARY DELIVERABLE ⭐)
```
Purpose: Clean aggregated summary
- One row per gvkey-year
- Contains: total_applications, ai_applications, ai_share, ai_dummy
- THIS is what gets submitted
```

---

## AI Classification

### CPC Code-Based (High Precision)
**AI-related CPC codes:**
- G06N3 - Neural networks
- G06N5 - Knowledge-based models
- G06N7 - Probabilistic/fuzzy logic
- G06N10 - Quantum computing
- G06N20 - Machine learning

**Limitation:** Only available for granted patents

### Keyword-Based (High Recall)
**AI keywords:**
- machine learning, deep learning, neural network
- artificial intelligence, reinforcement learning
- computer vision, natural language processing
- random forest, gradient boosting, etc.

**Advantage:** Works for pending applications

### Hybrid Approach (Recommended)
Mark as AI if **either** method flags it:
```
is_ai = (is_ai_cpc OR is_ai_keyword)
```

Track classification method:
- `cpc` - CPC codes only
- `keyword` - Keywords only
- `both` - Both methods

---

## Memory Efficiency

### For Large Files (PatentsView tables can be 2-6 GB each)

**Strategy 1: Use DuckDB**
```python
import duckdb
con = duckdb.connect('patents.ddb')

# SQL filtering before loading into pandas
df = con.execute("""
    SELECT * FROM applications
    WHERE filing_year >= 2000
""").df()
```

**Strategy 2: Chunked Reading**
```python
for chunk in pd.read_csv('large_file.tsv', chunksize=100000):
    process(chunk)
```

**Strategy 3: Optimize Data Types**
```python
dtypes = {
    'gvkey': 'category',
    'year': 'int16',
    'is_ai': 'bool'
}
```

See `IMPLEMENTATION_GUIDE.md` for detailed strategies.

---

## Prerequisites

### Required Python Libraries
```bash
pip install pandas numpy duckdb
```

### Optional (for enhanced functionality)
```bash
pip install rapidfuzz psutil tqdm
```

### PatentsView Data
Tables will be auto-downloaded by the notebook:
- g_application (~2-3 GB)
- pg_applicant_not_disambiguated (~1-2 GB)
- g_cpc_current (~4 GB, may already exist from Task1)
- g_patent_abstract (~6 GB, may already exist from Task1)

**Total download:** ~10-15 GB
**Time estimate:** 10-30 minutes (depending on connection)

### DISCERN 2 (Optional, Recommended)
Download separately from: https://zenodo.org/records/13619821

Used for improved gvkey mapping. The notebook includes a fallback method using clinical trials data if DISCERN 2 is unavailable.

---

## Expected Runtime

**With typical hardware (8GB RAM, SSD):**
- Data download: 10-30 minutes
- Data import: 5-10 minutes
- AI classification: 5-15 minutes
- Aggregation & export: 1-2 minutes

**Total:** ~30-60 minutes

**Note:** First run downloads data; subsequent runs are faster.

---

## Key Features

✅ **Memory-efficient:** Uses DuckDB for large files
✅ **Reproducible:** All steps documented in notebook
✅ **Flexible:** Two-layer architecture allows easy modifications
✅ **Validated:** Includes validation checks and summary statistics
✅ **Well-documented:** Extensive comments and markdown cells
✅ **Research-ready:** Output datasets ready for analysis

---

## Validation Checklist

Before using the output datasets, verify:

- [ ] Match rate: >50% of clinical trial firms matched to patents
- [ ] AI share: 1-10% of applications flagged as AI (typical range)
- [ ] Temporal trend: AI patents increase over time (2000-2025)
- [ ] Sample review: Manually check 10-20 AI-flagged patents
- [ ] No duplicates: Unique application_id in patent-level dataset
- [ ] Firm-year counts: Sum of firm-year totals matches patent-level count

---

## Troubleshooting

### Issue: Download fails
**Solution:** Check internet connection, increase timeout, or download manually

### Issue: Memory error
**Solution:** Use DuckDB instead of pandas, process year-by-year, or use smaller chunks

### Issue: Low match rate
**Solution:** Improve name cleaning function, integrate DISCERN 2, or use fuzzy matching

### Issue: No AI patents found
**Solution:** Verify CPC table loaded, check keyword patterns, review sample patents

See `IMPLEMENTATION_GUIDE.md` for detailed troubleshooting.

---

## File Structure

```
Task2/
├── README.md                              # This file
├── IMPLEMENTATION_GUIDE.md                # Detailed documentation
├── task2_patents_discern_merge.ipynb      # Main analysis notebook
├── clinical_trial_sample (1).csv          # Input: Clinical trials data
├── RA Task #2.pdf                         # Original task description
│
├── [Generated by notebook:]
├── task2_patents.ddb                      # DuckDB database
├── patent_level_dataset.csv               # Output: Patent-level data
├── firm_year_patents.csv                  # Output: Firm-year patents
└── firm_year_merged.csv                   # Output: Final merged dataset
```

---

## Next Steps

After completing this task:

1. **Validation:** Review sample of AI-classified patents
2. **DISCERN 2:** Integrate for improved gvkey matching
3. **Extended Analysis:** Examine temporal trends, firm-specific patterns
4. **Task #2 Part 2:** NCT ID - PubMed linkage (separate notebook)

---

## References

- **PatentsView:** https://patentsview.org/download/data-download-tables
- **DISCERN 2:** https://zenodo.org/records/13619821
- **CPC Codes:** https://www.cooperativepatentclassification.org/
- **Task Description:** See `RA Task #2.pdf`

---

## Questions or Issues?

Review the `IMPLEMENTATION_GUIDE.md` for:
- Detailed methodology
- Best practices
- Troubleshooting
- Validation procedures

**Last Updated:** February 14, 2026
